name: Build Packer images
on:
  workflow_call:
    inputs:
      product_name:
        required: true
        type: string
      ros_distro:
        required: true
        type: string
      with_simulation:
        required: false
        type: string
        default: true
      is_external_project:
        required: false
        type: boolean
        default: false
      propagate_project:
        required: false
        type: boolean
        default: false

    secrets:
      auto_commit_user:
        required: true
      auto_commit_mail:
        required: true
      auto_commit_pwd:
        required: true
      registry_user:
        required: true
      registry_password:
        required: true
      nexus_publisher_user:
        required: true
      nexus_publisher_password:
        required: true
      gh_token:
        required: true
      aws_key_id:
        required: true
      aws_secret_key_id:
        required: true
      slack_token_id:
        required: true
      proxmox_api_url:
        required: true
      proxmox_api_token_id:
        required: true
      proxmox_api_token_secret:
        required: true
      ssh_pem_fleet_aws_vm:
        required: true


env:
  CI_INTEGRATION_SCRIPTS_VERSION: "2.2.0.7"
  MOBTEST_VERSION: "0.0.4.2"
  PACKAGE_DEPLOYER_VERSION: "1.0.0.25"
  GITHUB_API_USR: "OttoMation-Movai"
  AWS_ACCESS_KEY_ID: ${{ secrets.aws_key_id }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret_key_id }}
  REGISTRY: registry.hel.mov.ai
  PUSH_REGISTRY: registry.cloud.mov.ai
  USERSPACE_FOLDER_PATH: userspace
  REMOTE_WORKSPACE: workspace

jobs:
  Validate-boostrap-configs:
    runs-on: integration-pipeline
    container:
      image: registry.aws.cloud.mov.ai/devops/py-buildserver:latest
      credentials:
        username: ${{secrets.registry_user}}
        password: ${{secrets.registry_password}}
    steps:
      - name: Checkout
        uses: actions/checkout@v3

      - name: Validate Manifest
        shell: bash
        run: |
          apt install -y yamllint
          yamllint product-manifest.yaml

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: Bootstraping simulator metadata
        run: |
          git config --global --add safe.directory $(pwd)
          git fetch
          git checkout origin/${GITHUB_REF#refs/heads/} -- product.version
          cat product.version
          rm -rf simulator_artifacts ci_artifacts

          merge_manifest_args=" --dependency_name product-platform"
          merge_manifest_args="$merge_manifest_args --gh_api_user $GITHUB_API_USR"
          merge_manifest_args="$merge_manifest_args --gh_api_pwd ${{ secrets.auto_commit_pwd }}"
          merge_manifest_args="$merge_manifest_args --auto_fetch"

          if [ "${{ inputs.is_external_project }}" = "true" ];
          then
            merge_manifest_args="$merge_manifest_args --merge_sub_prod_dep_keys platform_config,platform_components,installion"
          fi

          if [ "${{ inputs.with_simulation }}" = "false" ];
          then
            merge_manifest_args="$merge_manifest_args --forward_sim"
          fi

          integration-pipeline merge_manifest_dependency $merge_manifest_args

          if [ "${{ inputs.with_simulation }}" = "true" ];
          then
          integration-pipeline generate_meta_simulator_artifacts \
                --manifest_platform_base_key product_dependencies \
                --product_name ${{ inputs.product_name }} \
                --branch ${GITHUB_REF#refs/heads/} \
                --update_simulator \
                --docker_registry $REGISTRY

          mkdir simulator_artifacts
          cp ci_artifacts/* ./simulator_artifacts
          fi

      - name: Stash sim_configs
        if: ${{ inputs.with_simulation == 'true' }}
        uses: actions/upload-artifact@v3
        with:
          name: sim_configs
          path: simulator_artifacts/*

      - name: raise
        run: |
          rm -rf simulator_artifacts ci_artifacts
          mkdir platform_configs
          integration-pipeline raise
          cp product.version ./platform_configs/product.version
          cp product-manifest.yaml ./platform_configs/product-manifest.yaml

      - name: Stash raised_meta
        uses: actions/upload-artifact@v3
        with:
          name: raised_meta
          path: platform_configs/*

  Build-Spawner:
    needs: [Validate-boostrap-configs]
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.ros_distro) }}
    runs-on: integration-pipeline
    outputs:
      raised_version: ${{ steps.pre_build.outputs.raised_version }}
    steps:
      - uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        run: |
          echo "public ip: $(curl ipinfo.io/ip)"
          echo "private ip: $(hostname -I | awk '{print $1}')"

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash raised_meta
        uses: actions/download-artifact@v3
        with:
          name: raised_meta
          path: platform_configs

      - name: Generate product configs from manifest
        shell: bash
        run: |
          cp ./platform_configs/product.version product.version
          cp ./platform_configs/product-manifest.yaml product-manifest.yaml
          export PATH="$HOME/.local/bin:$PATH"
          cat product-manifest.yaml
          integration-pipeline generate_meta_artifacts --update_simulator --override_spawner ${{ inputs.product_name }} --manifest_platform_base_key "product_dependencies"

      - name: Stash manifest
        uses: actions/upload-artifact@v3
        with:
          name: manifest
          path: product-manifest.yaml

      - name: Lint docker image
        shell: bash
        run: |
          wget https://github.com/hadolint/hadolint/releases/download/v2.9.3/hadolint-Linux-x86_64
          chmod +x hadolint-Linux-x86_64
          ./hadolint-Linux-x86_64 docker/${{ matrix.distro }}/Dockerfile -t error

      - name: Login to ${{ env.REGISTRY }} Registry
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.REGISTRY }}

      - name: Login to ${{ env.PUSH_REGISTRY }} Registry
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.registry_user }}
          password: ${{ secrets.registry_password }}
          registry: ${{ env.PUSH_REGISTRY }}

      - name: Prepare docker build variables
        id: pre_build
        run: |
          #echo ::set-output name=base_name::$(cat ci_artifacts/spawner_base_name_${{ matrix.distro }}.ci)
          #echo ::set-output name=base_version::$(cat ci_artifacts/spawner_base_version_${{ matrix.distro }}.ci)
          #echo ::set-output name=raised_version::$(cat product.version)
          echo "base_name=$(cat ci_artifacts/spawner_base_name_${{ matrix.distro }}.ci)" >> $GITHUB_OUTPUT
          echo "base_version=$(cat ci_artifacts/spawner_base_version_${{ matrix.distro }}.ci)" >> $GITHUB_OUTPUT
          echo "raised_version=$(cat product.version)" >> $GITHUB_OUTPUT

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
      # - name: Docker build
      #   shell: bash
      #   run: |
      #     docker build --add-host ${{ env.REGISTRY }}:172.22.0.106 \
      #       --build-arg DOCKER_REGISTRY=${{ env.REGISTRY }} \
      #       --build-arg BASE_IMAGE=${{ steps.pre_build.outputs.base_name }} \
      #       --build-arg TAG=${{ steps.pre_build.outputs.base_version }} \
      #       --build-arg CI_SCRIPT_VERSION=${{ env.CI_INTEGRATION_SCRIPTS_VERSION }} \
      #       --file docker/${{ matrix.distro }}/Dockerfile \
      #       --platform linux/amd64 \
      #       --tag ${{ env.PUSH_REGISTRY }}/ci/${{ inputs.product_name }}-${{ matrix.distro }}:${{ steps.pre_build.outputs.raised_version }} \
      #       --pull \
      #       --push .


      - name: Stash robot_jsons_${{ matrix.distro }}
        uses: actions/upload-artifact@v3
        with:
          name: robot_jsons_${{ matrix.distro }}
          path: "*.json*"

      - name: Docker cleanups
        if: always()
        shell: bash
        run: |
          docker system prune -f
          docker image prune --all -f

  Install-Simulator-Robot:
    needs: [Build-Spawner]
    strategy:
      matrix:
        distro: ${{ fromJSON(inputs.ros_distro) }}
    runs-on: integration-pipeline-simulation
    steps:
      - uses: rtCamp/action-cleanup@master
      - name: Checkout
        uses: actions/checkout@v3

      - name: Agent info
        run: |
          echo "public ip: $(curl ipinfo.io/ip)"
          echo "private ip: $(hostname -I | awk '{print $1}')"

      - name: Install CI Scripts
        shell: bash
        run: python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed

      - name: unstash raised_meta
        uses: actions/download-artifact@v3
        with:
          name: raised_meta
          path: .

      - name: unstash manifest
        uses: actions/download-artifact@v3
        with:
          name: manifest
          path: .

      - name: unstash sim_configs
        uses: actions/download-artifact@v3
        with:
          name: sim_configs
          path: simulator_artifacts

      - name: unstash robot_jsons_${{ matrix.distro }}
        uses: actions/download-artifact@v3
        with:
          name: robot_jsons_${{ matrix.distro }}
          path: .

      - name: Install terraform
        shell: bash
        run: |
          wget -O- https://apt.releases.hashicorp.com/gpg | gpg --dearmor | sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
          sudo apt update && sudo apt install terraform -y

      - name: Setup terraform proxmox provisioner
        id: provision_infra_setup
        shell: bash
        run: |
          provision_infra_dir=provision_scripts
          provision_infra_version=0.1.0-2
          provision_infra_repo_name=devops-tf-proxmox-fleet

          rm -rf $provision_infra_dir
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline fetch_by_tag --repo $provision_infra_repo_name --version $provision_infra_version --gh_api_user $GITHUB_API_USR --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $provision_infra_dir
          ls -la $provision_infra_dir
          echo "target_dir=${provision_infra_dir}/hosts/generic/" >> $GITHUB_OUTPUT

      - name: Define Instance names
        id: infra_names
        shell: bash
        run: |
          branch=$(echo ${GITHUB_REF#refs/heads/} | sed "s;\.;-;g" )

          local_manager_prefix="ip-$branch-standalone"
  
          echo "$local_manager_prefix"

          echo "simul_prefix=${local_manager_prefix}" >> $GITHUB_OUTPUT

      - name: Provision remote vms (Proxmox)
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        shell: bash
        run: |
          terraform init -backend-config="key=mary-standalone-${{ steps.infra_names.outputs.simul_prefix }}.tfstate"
          terraform plan
          terraform apply -auto-approve

          echo "${{ secrets.ssh_pem_fleet_aws_vm }}" > ~/.ssh/aws_slave.pem
          sudo chmod 600 ~/.ssh/aws_slave.pem

        env:
          TF_VAR_number_agents: 0
          TF_VAR_proxmox_api_url: ${{ secrets.proxmox_api_url }}
          TF_VAR_proxmox_api_token_id: ${{ secrets.proxmox_api_token_id }}
          TF_VAR_proxmox_api_token_secret: ${{ secrets.proxmox_api_token_secret }}
          TF_VAR_provision_ssh_pem: ${{ secrets.ssh_pem_fleet_aws_vm }}
          TF_VAR_ip_list: '["dhcp"]'
          TF_VAR_storage: "local-lvm"
          TF_VAR_proxmox_host: "mary"
          TF_VAR_vm_gateway: "10.10.1.254"
          TF_VAR_ip_mask: 23
          TF_VAR_bios: "ovmf"
          TF_VAR_pool: "IP-Temp-VMs"
          TF_VAR_tags: "ip-simul-ci"
          TF_VAR_fleet_hosts_user: "devops"
          TF_VAR_template_name: "u22dci-gpu"
          TF_VAR_fleet_manager_name: ${{ steps.infra_names.outputs.simul_prefix }}
          TF_VAR_fleet_manager_memory: 16000
          TF_VAR_fleet_manager_cores: 10

      - name: Gather Terraform outputs
        working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
        id: infra_outputs
        shell: bash
        run: |
          ip=$(terraform output manager_ip_address)
          user=$(terraform output user)
          echo "host_ip=$(echo $ip | sed "s;\";;g")" >> $GITHUB_OUTPUT
          echo "host_user=$(echo $user | sed "s;\";;g")" >> $GITHUB_OUTPUT

      - name: Configure SSH
        id: remote_ssh_setup
        shell: bash
        run: |
          ssh-keygen -f ~/.ssh/known_hosts -R ${{ steps.infra_outputs.outputs.host_ip }} || true
          ssh-keyscan -H ${{ steps.infra_outputs.outputs.host_ip }} >> ~/.ssh/known_hosts || true
          
          test -f ~/.ssh/config
          CONFIG_FILE_EXISTS=1
          if [ $? -eq 0 ]; then
            mv ~/.ssh/config ~/.ssh/config.bak
            CONFIG_FILE_EXISTS=0
          fi
          
          touch ~/.ssh/config
          echo "Host robot" >> ~/.ssh/config
          echo "  HostName ${{ steps.infra_outputs.outputs.host_ip }}" >> ~/.ssh/config
          echo "  User ${{ steps.infra_outputs.outputs.host_user }}" >> ~/.ssh/config
          echo "  IdentityFile ~/.ssh/aws_slave.pem" >> ~/.ssh/config
          echo "  StrictHostKeyChecking no" >> ~/.ssh/config
          cat ~/.ssh/config

          ssh robot 'rm -rf ./${{ env.REMOTE_WORKSPACE }}; mkdir -p ./${{ env.REMOTE_WORKSPACE }}'

          echo "config_pre_exists=$CONFIG_FILE_EXISTS" >> $GITHUB_OUTPUT

      - name: Remote - Agent info
        id: agent_info
        run: |
          ssh robot '
            ip=$(hostname -I | awk "{print $1}")
            echo $ip
          '

      - name: Remote - Login to Private Registry
        shell: bash
        run: ssh robot "docker login ${{ env.REGISTRY }} -u ${{ secrets.registry_user }} -p ${{ secrets.registry_password }}"

      - name: Remote - Install requirements
        shell: bash
        run: ssh robot "sudo apt install python3-pip -y"

      - name: Remote - FAKE Docker load spawner image
        shell: bash
        run: |
          ssh robot '
            docker pull "${{ env.REGISTRY }}/ci/spawner-tugbot-noetic:2.4.0-77"
            docker tag "${{ env.REGISTRY }}/ci/spawner-tugbot-noetic:2.4.0-77" "${{ env.REGISTRY }}/qa/spawner-tugbot-noetic:0.1.0-1"
          '

      # - name: Remote - Docker load spawner image
      #   shell: bash
      #   run: |
      #     docker pull "${{ env.REGISTRY }}/ci/${{ inputs.product_name }}-${{ matrix.distro }}:${{ needs.Build-Spawner.outputs.raised_version }}"
      #     docker tag "${{ env.REGISTRY }}/ci/${{ inputs.product_name }}-${{ matrix.distro }}:${{ needs.Build-Spawner.outputs.raised_version }}" "${{ env.REGISTRY }}/qa/${{ inputs.product_name }}-${{ matrix.distro }}:${{ needs.Build-Spawner.outputs.raised_version }}"

      - name: Remote - Fake Docker load simulator image
        shell: bash
        run: |
          ssh robot '
            docker pull ${{ env.REGISTRY }}/qa/tugbot-ign-sim:v2.4.0-36
            docker tag ${{ env.REGISTRY }}/qa/tugbot-ign-sim:v2.4.0-36 ${{ env.REGISTRY }}/qa/tugbot-ign-sim:v0.1.0-0
          '

      # - name: Remote - Docker load simulator image
      #   shell: bash
      #   run: |
      #     promoted_name=$(echo "${{ needs.Build-Simulator.outputs.image_name }}" | sed "s-/ci/-/qa/-g")
      #     docker pull "${{ needs.Build-Simulator.outputs.image_name }}"
      #     docker tag "${{ needs.Build-Simulator.outputs.image_name }}" $promoted_name

      - name: Remote - Install CI Scripts
        shell: bash
        run: ssh robot "python3 -m pip install integration-pipeline==$CI_INTEGRATION_SCRIPTS_VERSION --ignore-installed"

      - name: Remote - unstash manifest
        shell: bash
        run: scp product-manifest.yaml robot:${{ env.REMOTE_WORKSPACE }}/product-manifest.yaml

      - name: Remote - unstash sim_configs
        shell: bash
        run: scp -r simulator_artifacts robot:${{ env.REMOTE_WORKSPACE }}/simulator_artifacts

      - name: Remote - unstash robot_jsons_${{ matrix.distro }}
        shell: bash
        run: scp -r *.json* robot:${{ env.REMOTE_WORKSPACE }}/

      - name: list workspace
        shell: bash
        run: |
          ssh robot 'cd ${{ env.REMOTE_WORKSPACE }}; ls -la'

      - name: Remote - Setup QA Simulation tests
        shell: bash
        id: simulator_tests_setup
        run: |
          ssh robot '
            set -e
            cd ${{ env.REMOTE_WORKSPACE }}

            qa_key=simulator_tests

            rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/test_set.txt
            export PATH="$HOME/.local/bin:$PATH"
  
            integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.target_dir --output_file /tmp/target_dir.txt
            integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.version --output_file /tmp/version.txt
            integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.name --output_file /tmp/repo_name.txt
            integration-pipeline get_yml_value --file product-manifest.yaml --key product_components.qa.$qa_key.test_set --output_file /tmp/test_set.txt
  
            tests_dir=$(cat /tmp/target_dir.txt)
            tests_version=$(cat /tmp/version.txt)
            tests_repo_name=$(cat /tmp/repo_name.txt)
            test_set=$(cat /tmp/test_set.txt)

            rm -rf $tests_repo_name
            integration-pipeline fetch_by_tag --repo $tests_repo_name --version $tests_version --gh_api_user ${{ env.GITHUB_API_USR }} --gh_api_pwd ${{ secrets.auto_commit_pwd }} --target_dir $tests_dir
            ls -la $tests_dir

            sudo apt install python3.8-venv -y

            # setup venv in a step that is always executed
            pushd "${tests_dir}"
            rm -rf venv
            python3 -m venv venv
            . venv/bin/activate
            python3 -m pip install --upgrade pip
            pip install -i https://artifacts.cloud.mov.ai/repository/pypi-integration/simple --extra-index-url https://pypi.org/simple -r requirements.txt
            deactivate
            popd

          '
          rm -f /tmp/target_dir.txt /tmp/version.txt /tmp/repo_name.txt /tmp/test_set.txt
          scp -r robot:/tmp/*.txt /tmp/

          echo "target_dir=$(cat /tmp/target_dir.txt)" >> $GITHUB_OUTPUT
          echo "version=$(cat /tmp/version.txt)" >> $GITHUB_OUTPUT
          echo "test_set=$(cat /tmp/test_set.txt)" >> $GITHUB_OUTPUT

      - name: Remote - Install
        id: install
        shell: bash
        run: |
          ssh robot '
          set -e
          cd ${{ env.REMOTE_WORKSPACE }}

          for robot in $(movai-cli robots list); do
            movai-cli robots stop $robot
            sleep 5
            movai-cli robots remove $robot
          done || true

          mkdir -p artifacts
          cp *.json artifacts/
          CONFIG_FILE_NAME="standalone-${{ inputs.product_name }}-simulator-${{ matrix.distro }}.json"
          export PATH="$HOME/.local/bin:$PATH"
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key services_version --output_file movai_service_version
          integration-pipeline get_json_value --file $CONFIG_FILE_NAME.ci --key quickstart_version --output_file quickstart_version

          #workaround ubuntu 22.04
          sudo apt install python3.8-distutils -y
          sudo ln -s /usr/lib/python3/dist-packages/_dbus_bindings.cpython-310-x86_64-linux-gnu.so /usr/lib/python3/dist-packages/_dbus_bindings.so
          sudo ln -s /usr/lib/python3/dist-packages/_dbus_glib_bindings.cpython-310-x86_64-linux-gnu.so /usr/lib/python3/dist-packages/_dbus_glib_bindings.so

          export USERSPACE_FOLDER_PATH="$(pwd)/userspace"
          export PUBLIC_IP=$(hostname -I | awk '{print $1}')
          export SIMULATION_ID="CI"
          export DISPLAY=":1"
          rm -rf userspace

          wget https://movai-scripts.s3.amazonaws.com/QuickStart_$(cat quickstart_version).bash
          chmod +x ./QuickStart_$(cat quickstart_version).bash
          ./QuickStart_$(cat quickstart_version).bash --apps $(cat movai_service_version) $CONFIG_FILE_NAME
          MOVAI_USER="ci"
          MOVAI_PWD="4Iva6UHAQq9DGITj"
          for robot in $(movai-cli robots list); do
            movai-cli robots user "$robot" "$MOVAI_USER" "$MOVAI_PWD"
          done

          execution_status=$?
          exit $execution_status
          rm movai_service_version
          '
          echo "movai_user=ci" >> $GITHUB_OUTPUT
          echo "movai_pwd=4Iva6UHAQq9DGITj" >> $GITHUB_OUTPUT

      - name: Remote - Simulation Tests
        shell: bash
        run: |
          ssh robot '
            set -e
            cd ${{ env.REMOTE_WORKSPACE }}/${{ steps.simulator_tests_setup.outputs.target_dir }}

            # install test dependencies on host
            sudo apt install -y --allow-downgrades python3-rosnode python3-rosparam python3-rostopic
            export PYTHONPATH="${PYTHONPATH}:/usr/lib/python3/dist-packages"

            # install test dependencies on spawner
            ## get spawner container name
            CONTAINER_ID=$(docker ps --format '{{.Names}}' --filter "name=^spawner-.*")
            ## get apt dependencies
            #APT_DEPS=$(cat apt-requirements.txt | tr "\n" " ")
            ## install
            # docker exec -t "${CONTAINER_ID}" bash -c "
            #   sudo apt update
            #   sudo apt install -y ${APT_DEPS}
            # "

            # run tests
            . venv/bin/activate

            pytest \
              -s \
              -ra \
              --movai-user ${{ steps.install.outputs.movai_user }} \
              --movai-pw ${{ steps.install.outputs.movai_pwd }} \
              --tb=short

            deactivate
          '

      - name: Remote - Save docker container logs
        if: always()
        shell: bash
        run: |
          ssh robot '

            cd ${{ env.REMOTE_WORKSPACE }}/${{ steps.simulator_tests_setup.outputs.target_dir }}

            # for sanity
            docker ps -a

            # backend
            CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^backend-.*")
            docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

            # spawner
            CONTAINER_ID=$(docker ps -a --format '{{.Names}}' --filter "name=^spawner-.*")
            docker logs "${CONTAINER_ID}" &> "${CONTAINER_ID}.log"

            # movai-service
            journalctl -u movai-service --since '1hour ago' &> "movai-service.log"
            
            # spawner (mobros firmware)
            journalctl -u movai-service -t mobros --since '1hour ago' &> spawner-firmware.log || true
          '

      - name: Remote - Stash QA artifacts
        if: always()
        shell: bash
        run: |
          ssh robot '
            cd ${{ env.REMOTE_WORKSPACE }}

            # cleanup
            rm -rf qa_artifacts

            # tests artifacts
            # *.log might not exist if the test fails early
            mkdir -p qa_artifacts
            cp -r "${{ steps.simulator_tests_setup.outputs.target_dir }}"/*.log ./qa_artifacts || true
          '
          scp -r robot:${{ env.REMOTE_WORKSPACE }}/qa_artifacts .


      - name: Stash QA artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: qa_artifacts_simulator_tests
          path: qa_artifacts/*
  
      - name: Teardown ssh setup
        shell: bash
        run: |
          if [ "${{ steps.remote_ssh_setup.outputs.config_pre_exists }}" = "0" ];
          then
            rm ~/.ssh/config
            mv ~/.ssh/config.bak ~/.ssh/config
          fi

      # - name: Teardown remote vms (Proxmox)
      #   working-directory: ${{ steps.provision_infra_setup.outputs.target_dir }}
      #   if: ${{ success() || cancelled() || ( !inputs.debug_fleet_keep_alive && failure() ) }}
      #   shell: bash
      #   run: terraform destroy -auto-approve
      #   env:
      #     TF_VAR_number_agents: ${{ inputs.fleet_number_members }}
      #     TF_VAR_proxmox_api_url: "https://hel.mov.ai:8006/api2/json"
      #     TF_VAR_proxmox_api_token_id: ${{ secrets.proxmox_api_token_id }}
      #     TF_VAR_proxmox_api_token_secret: ${{ secrets.proxmox_api_token_secret }}
      #     TF_VAR_provision_ssh_pem: ${{ secrets.ssh_pem_fleet_aws_vm }}
      #     TF_VAR_ip_list: ${{ inputs.fleet_ips }}